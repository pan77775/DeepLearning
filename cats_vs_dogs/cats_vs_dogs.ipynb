{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from zipfile import ZipFile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries for Deep Learning\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir=\"D:/programming/kaggle/cats_vs_dogs/dataset/test_set\"\n",
    "train_dir=\"D:/programming/kaggle/cats_vs_dogs/dataset/training_set\"\n",
    "\n",
    "train_dir_cats = train_dir + '/cats'\n",
    "train_dir_dogs = train_dir + '/dogs'\n",
    "test_dir_cats = test_dir + '/cats'\n",
    "test_dir_dogs = test_dir + '/dogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of cats training images -  4000\n",
      "number of dogs training images -  4000\n",
      "number of cats testing images -  1000\n",
      "number of dogs testing images -  1000\n"
     ]
    }
   ],
   "source": [
    "print('number of cats training images - ',len(os.listdir(train_dir_cats)))\n",
    "print('number of dogs training images - ',len(os.listdir(train_dir_dogs)))\n",
    "print('number of cats testing images - ',len(os.listdir(test_dir_cats)))\n",
    "print('number of dogs testing images - ',len(os.listdir(test_dir_dogs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(rescale = 1.0/255.0, zoom_range = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_data = data_generator.flow_from_directory(directory = train_dir,\n",
    "                                                   target_size = (64, 64),\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   class_mode = 'binary')\n",
    "testing_data = data_generator.flow_from_directory(directory = test_dir,\n",
    "                                                  target_size = (64, 64),\n",
    "                                                  batch_size = batch_size,\n",
    "                                                  class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the layers in the Convolutional Deep Neural Network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, 3, activation = 'relu', input_shape = training_data.image_shape))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Dropout(rate = 0.2))\n",
    "model.add(Conv2D(64, 3, activation = 'relu'))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Dropout(rate = 0.2))\n",
    "model.add(Conv2D(64, 3, activation = 'relu'))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Dropout(rate = 0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dropout(rate = 0.2))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(rate = 0.2))\n",
    "model.add(Dense(units = len(set(training_data.classes)), activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                73760     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 132,322\n",
      "Trainable params: 132,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 31s 247ms/step - loss: 0.6850 - acc: 0.5485\n",
      "500/500 [==============================] - 179s 358ms/step - loss: 0.6897 - acc: 0.5389 - val_loss: 0.6850 - val_acc: 0.5485\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 30s 243ms/step - loss: 0.6439 - acc: 0.6500\n",
      "500/500 [==============================] - 184s 368ms/step - loss: 0.6700 - acc: 0.5838 - val_loss: 0.6439 - val_acc: 0.6500\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 32s 256ms/step - loss: 0.5924 - acc: 0.6955\n",
      "500/500 [==============================] - 179s 357ms/step - loss: 0.6247 - acc: 0.6488 - val_loss: 0.5924 - val_acc: 0.6955\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 31s 250ms/step - loss: 0.5904 - acc: 0.6785\n",
      "500/500 [==============================] - 181s 362ms/step - loss: 0.5985 - acc: 0.6790 - val_loss: 0.5904 - val_acc: 0.6785\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 31s 248ms/step - loss: 0.5530 - acc: 0.7230\n",
      "500/500 [==============================] - 177s 353ms/step - loss: 0.5773 - acc: 0.6965 - val_loss: 0.5530 - val_acc: 0.7230\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 31s 247ms/step - loss: 0.5822 - acc: 0.6890\n",
      "500/500 [==============================] - 176s 353ms/step - loss: 0.5609 - acc: 0.7139 - val_loss: 0.5822 - val_acc: 0.6890\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 31s 245ms/step - loss: 0.5396 - acc: 0.7340\n",
      "500/500 [==============================] - 179s 359ms/step - loss: 0.5482 - acc: 0.7209 - val_loss: 0.5396 - val_acc: 0.7340\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 31s 249ms/step - loss: 0.5400 - acc: 0.7310\n",
      "500/500 [==============================] - 180s 359ms/step - loss: 0.5265 - acc: 0.7416 - val_loss: 0.5400 - val_acc: 0.7310\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 31s 247ms/step - loss: 0.5200 - acc: 0.7385\n",
      "500/500 [==============================] - 177s 354ms/step - loss: 0.5147 - acc: 0.7477 - val_loss: 0.5200 - val_acc: 0.7385\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 33s 264ms/step - loss: 0.5266 - acc: 0.7295\n",
      "500/500 [==============================] - 182s 364ms/step - loss: 0.4912 - acc: 0.7630 - val_loss: 0.5266 - val_acc: 0.7295\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 31s 248ms/step - loss: 0.5096 - acc: 0.7445\n",
      "500/500 [==============================] - 187s 373ms/step - loss: 0.4958 - acc: 0.7600 - val_loss: 0.5096 - val_acc: 0.7445\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 31s 250ms/step - loss: 0.4680 - acc: 0.7775\n",
      "500/500 [==============================] - 179s 358ms/step - loss: 0.4719 - acc: 0.7740 - val_loss: 0.4680 - val_acc: 0.7775\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 31s 252ms/step - loss: 0.4624 - acc: 0.7790\n",
      "500/500 [==============================] - 177s 354ms/step - loss: 0.4644 - acc: 0.7807 - val_loss: 0.4624 - val_acc: 0.7790\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 34s 270ms/step - loss: 0.4860 - acc: 0.7690\n",
      "500/500 [==============================] - 187s 375ms/step - loss: 0.4621 - acc: 0.7816 - val_loss: 0.4860 - val_acc: 0.7690\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 32s 253ms/step - loss: 0.4703 - acc: 0.7770\n",
      "500/500 [==============================] - 182s 365ms/step - loss: 0.4540 - acc: 0.7879 - val_loss: 0.4703 - val_acc: 0.7770\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 31s 250ms/step - loss: 0.4503 - acc: 0.8005\n",
      "500/500 [==============================] - 177s 354ms/step - loss: 0.4422 - acc: 0.7944 - val_loss: 0.4503 - val_acc: 0.8005\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 31s 246ms/step - loss: 0.4691 - acc: 0.7795\n",
      "500/500 [==============================] - 176s 352ms/step - loss: 0.4326 - acc: 0.7965 - val_loss: 0.4691 - val_acc: 0.7795\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 32s 253ms/step - loss: 0.4400 - acc: 0.8025\n",
      "500/500 [==============================] - 181s 363ms/step - loss: 0.4264 - acc: 0.7997 - val_loss: 0.4400 - val_acc: 0.8025\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 31s 244ms/step - loss: 0.4407 - acc: 0.7945\n",
      "500/500 [==============================] - 179s 357ms/step - loss: 0.4242 - acc: 0.8029 - val_loss: 0.4407 - val_acc: 0.7945\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 31s 251ms/step - loss: 0.4924 - acc: 0.7695\n",
      "500/500 [==============================] - 178s 356ms/step - loss: 0.4078 - acc: 0.8115 - val_loss: 0.4924 - val_acc: 0.7695\n"
     ]
    }
   ],
   "source": [
    "fitted_model = model.fit_generator(training_data,\n",
    "                        steps_per_epoch = 2000,\n",
    "                        epochs = 20,\n",
    "                        validation_data = testing_data,\n",
    "                        validation_steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x212933951d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracy and validation accuracy\n",
    "accuracy = fitted_model.history['acc']\n",
    "plt.plot(range(len(accuracy)), accuracy, 'bo', label = 'accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model\n",
    "def testing_image(image_directory):\n",
    "    test_image = image.load_img(image_directory, target_size = (64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = model.predict(x = test_image)\n",
    "    print(result)\n",
    "    if result[0][0]  == 1:\n",
    "        prediction = 'Dog'\n",
    "    else:\n",
    "        prediction = 'Cat'\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]]\n",
      "Cat\n"
     ]
    }
   ],
   "source": [
    "print(testing_image(test_dir + '/cats/cat.4003.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
